{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKCupid Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, there has been a massive rise in the usage of dating apps to find love. Many of these apps use sophisticated data science techniques to recommend possible matches to users and to optimize user experience. These apps give us access to a wealth of information that we've never had before about how different people experience romance. In this project, data from OKCupid, an app that focuses on using multiple choice and short answers to match users, will be analysed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The OKCupid Dataset contains the following features:\n",
    "\n",
    "* `body_type`: multiple choice question with 12 possible answers: average, fit, athletic, thin, curvy, a litle extra, skinny, full figured, overweight, jacked, used up, and rather not say.\n",
    "* `diet`: Icluding variations of the options: anything, vegetarian, vegan, kosher, and halal\n",
    "* `drinks` : Abaut the person's drinking habits. Options are: desperately, very often, often, socially, rarely, and not at all.\n",
    "* `drugs` : The person's drug use, with the options never, sometimes, or often. \n",
    "* `Education`: The education level of the person, with 32 different options.\n",
    "* `essay 0` to `essay9`: Open short answers.\n",
    "* `ethnicity`. The ethnicity of the person.\n",
    "* `height`\n",
    "* `Income`: How much the person makes a year.\n",
    "* `job`: 21 possible answers.\n",
    "* `location`: where the person lives.\n",
    "* `offspring`: whether they have any offspring and whether they might want in the future (15 possible answers).\n",
    "* `orientation`: Sexual orientation. Options are: straight, gay, or bisexual.\n",
    "* `pets`: whether they like or dislike either dogs, cats or both and whether they have them as pets. 15 possible answers.\n",
    "* `religion`: The religion the person follows an how important it is for them. \n",
    "* `sex`: Male or Female.\n",
    "* `sign`: The horoscope sign and the importance the person places on horoscope. 48 possible answers.\n",
    "* `smokes`\" the smoking habbit of the person. Options are: yes, sometimes, when drinking, trying to quit, and no.\n",
    "* `speaks`: the language/s the person speaks and the level (either poorly, okay, or fluently).\n",
    "* `status`: the marital status, including the options: single, available, seeing someone, married, unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('profiles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        body_type               diet    drinks      drugs  \\\n",
       "0  a little extra  strictly anything  socially      never   \n",
       "1         average       mostly other     often  sometimes   \n",
       "2            thin           anything  socially        NaN   \n",
       "3            thin         vegetarian  socially        NaN   \n",
       "4        athletic                NaN  socially      never   \n",
       "\n",
       "                           education            ethnicity  height  income  \\\n",
       "0      working on college/university         asian, white    75.0      -1   \n",
       "1              working on space camp                white    70.0   80000   \n",
       "2     graduated from masters program                  NaN    68.0      -1   \n",
       "3      working on college/university                white    71.0   20000   \n",
       "4  graduated from college/university  asian, black, other    66.0      -1   \n",
       "\n",
       "                           job                                     offspring  \\\n",
       "0               transportation  doesn&rsquo;t have kids, but might want them   \n",
       "1         hospitality / travel  doesn&rsquo;t have kids, but might want them   \n",
       "2                          NaN                                           NaN   \n",
       "3                      student                       doesn&rsquo;t want kids   \n",
       "4  artistic / musical / writer                                           NaN   \n",
       "\n",
       "  orientation                       pets  \\\n",
       "0    straight  likes dogs and likes cats   \n",
       "1    straight  likes dogs and likes cats   \n",
       "2    straight                   has cats   \n",
       "3    straight                 likes cats   \n",
       "4    straight  likes dogs and likes cats   \n",
       "\n",
       "                                   religion sex  \\\n",
       "0     agnosticism and very serious about it   m   \n",
       "1  agnosticism but not too serious about it   m   \n",
       "2                                       NaN   m   \n",
       "3                                       NaN   m   \n",
       "4                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a subset of the dataset with the multiple choice questions only. \n",
    "mc = ['body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', 'height', 'income', 'job', 'offspring', 'orientation', 'pets', 'religion', 'sex', 'sign','smokes','speaks', 'status']\n",
    "mc_data = data[mc]\n",
    "mc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books:&lt;br /&gt;\\nabsurdistan, the republic, of mi...</td>\n",
       "      <td>food.&lt;br /&gt;\\nwater.&lt;br /&gt;\\ncell phone.&lt;br /&gt;\\n...</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet!&lt;br /&gt;\\nyou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories.&lt;br /...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement&lt;br /&gt;\\nconversation&lt;br /&gt;\\ncreation&lt;b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . .&lt;br /&gt;\\nlynch, j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians&lt;br /&gt;\\nat the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books:<br />\\nabsurdistan, the republic, of mi...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . .<br />\\nlynch, j...   \n",
       "4  music: bands, rappers, musicians<br />\\nat the...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0  food.<br />\\nwater.<br />\\ncell phone.<br />\\n...   \n",
       "1  delicious porkness in all of its glories.<br /...   \n",
       "2  movement<br />\\nconversation<br />\\ncreation<b...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet!<br />\\nyou...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a subset of the dataset with the open short questions\n",
    "oq = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9']\n",
    "oq_data = data[oq]\n",
    "oq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   body_type    54650 non-null  object \n",
      " 1   diet         35551 non-null  object \n",
      " 2   drinks       56961 non-null  object \n",
      " 3   drugs        45866 non-null  object \n",
      " 4   education    53318 non-null  object \n",
      " 5   ethnicity    54266 non-null  object \n",
      " 6   height       59943 non-null  float64\n",
      " 7   income       59946 non-null  int64  \n",
      " 8   job          51748 non-null  object \n",
      " 9   offspring    24385 non-null  object \n",
      " 10  orientation  59946 non-null  object \n",
      " 11  pets         40025 non-null  object \n",
      " 12  religion     39720 non-null  object \n",
      " 13  sex          59946 non-null  object \n",
      " 14  sign         48890 non-null  object \n",
      " 15  smokes       54434 non-null  object \n",
      " 16  speaks       59896 non-null  object \n",
      " 17  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(1), object(16)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "mc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54650</td>\n",
       "      <td>35551</td>\n",
       "      <td>56961</td>\n",
       "      <td>45866</td>\n",
       "      <td>53318</td>\n",
       "      <td>54266</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "      <td>51748</td>\n",
       "      <td>24385</td>\n",
       "      <td>59946</td>\n",
       "      <td>40025</td>\n",
       "      <td>39720</td>\n",
       "      <td>59946</td>\n",
       "      <td>48890</td>\n",
       "      <td>54434</td>\n",
       "      <td>59896</td>\n",
       "      <td>59946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>7647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14652</td>\n",
       "      <td>16585</td>\n",
       "      <td>41780</td>\n",
       "      <td>37724</td>\n",
       "      <td>23959</td>\n",
       "      <td>32831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7589</td>\n",
       "      <td>7560</td>\n",
       "      <td>51606</td>\n",
       "      <td>14814</td>\n",
       "      <td>2724</td>\n",
       "      <td>35829</td>\n",
       "      <td>1782</td>\n",
       "      <td>43896</td>\n",
       "      <td>21828</td>\n",
       "      <td>55697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       body_type             diet    drinks  drugs  \\\n",
       "count      54650            35551     56961  45866   \n",
       "unique        12               18         6      3   \n",
       "top      average  mostly anything  socially  never   \n",
       "freq       14652            16585     41780  37724   \n",
       "mean         NaN              NaN       NaN    NaN   \n",
       "std          NaN              NaN       NaN    NaN   \n",
       "min          NaN              NaN       NaN    NaN   \n",
       "25%          NaN              NaN       NaN    NaN   \n",
       "50%          NaN              NaN       NaN    NaN   \n",
       "75%          NaN              NaN       NaN    NaN   \n",
       "max          NaN              NaN       NaN    NaN   \n",
       "\n",
       "                                education ethnicity        height  \\\n",
       "count                               53318     54266  59943.000000   \n",
       "unique                                 32       217           NaN   \n",
       "top     graduated from college/university     white           NaN   \n",
       "freq                                23959     32831           NaN   \n",
       "mean                                  NaN       NaN     68.295281   \n",
       "std                                   NaN       NaN      3.994803   \n",
       "min                                   NaN       NaN      1.000000   \n",
       "25%                                   NaN       NaN     66.000000   \n",
       "50%                                   NaN       NaN     68.000000   \n",
       "75%                                   NaN       NaN     71.000000   \n",
       "max                                   NaN       NaN     95.000000   \n",
       "\n",
       "                income    job                offspring orientation  \\\n",
       "count     59946.000000  51748                    24385       59946   \n",
       "unique             NaN     21                       15           3   \n",
       "top                NaN  other  doesn&rsquo;t have kids    straight   \n",
       "freq               NaN   7589                     7560       51606   \n",
       "mean      20033.222534    NaN                      NaN         NaN   \n",
       "std       97346.192104    NaN                      NaN         NaN   \n",
       "min          -1.000000    NaN                      NaN         NaN   \n",
       "25%          -1.000000    NaN                      NaN         NaN   \n",
       "50%          -1.000000    NaN                      NaN         NaN   \n",
       "75%          -1.000000    NaN                      NaN         NaN   \n",
       "max     1000000.000000    NaN                      NaN         NaN   \n",
       "\n",
       "                             pets     religion    sex  \\\n",
       "count                       40025        39720  59946   \n",
       "unique                         15           45      2   \n",
       "top     likes dogs and likes cats  agnosticism      m   \n",
       "freq                        14814         2724  35829   \n",
       "mean                          NaN          NaN    NaN   \n",
       "std                           NaN          NaN    NaN   \n",
       "min                           NaN          NaN    NaN   \n",
       "25%                           NaN          NaN    NaN   \n",
       "50%                           NaN          NaN    NaN   \n",
       "75%                           NaN          NaN    NaN   \n",
       "max                           NaN          NaN    NaN   \n",
       "\n",
       "                                            sign smokes   speaks  status  \n",
       "count                                      48890  54434    59896   59946  \n",
       "unique                                        48      5     7647       5  \n",
       "top     gemini and it&rsquo;s fun to think about     no  english  single  \n",
       "freq                                        1782  43896    21828   55697  \n",
       "mean                                         NaN    NaN      NaN     NaN  \n",
       "std                                          NaN    NaN      NaN     NaN  \n",
       "min                                          NaN    NaN      NaN     NaN  \n",
       "25%                                          NaN    NaN      NaN     NaN  \n",
       "50%                                          NaN    NaN      NaN     NaN  \n",
       "75%                                          NaN    NaN      NaN     NaN  \n",
       "max                                          NaN    NaN      NaN     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "mostly anything        16585\n",
       "anything                6183\n",
       "strictly anything       5113\n",
       "mostly vegetarian       3444\n",
       "mostly other            1007\n",
       "strictly vegetarian      875\n",
       "vegetarian               667\n",
       "strictly other           452\n",
       "mostly vegan             338\n",
       "other                    331\n",
       "strictly vegan           228\n",
       "vegan                    136\n",
       "mostly kosher             86\n",
       "mostly halal              48\n",
       "strictly halal            18\n",
       "strictly kosher           18\n",
       "halal                     11\n",
       "kosher                    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.diet.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\3431613338.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['diet'] = mc_data['diet'].str.replace(r'^(strictly|mostly)\\s+', '', regex=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diet\n",
       "anything      27881\n",
       "vegetarian     4986\n",
       "other          1790\n",
       "vegan           702\n",
       "kosher          115\n",
       "halal            77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge categories in the feature `diet` for model simplification\n",
    "# Remove the prefixes 'mtrictly' or 'mostly' and any potential white spaces\n",
    "mc_data['diet'] = mc_data['diet'].str.replace(r'^(strictly|mostly)\\s+', '', regex=True)\n",
    "mc_data.diet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           14652\n",
       "fit               12711\n",
       "athletic          11819\n",
       "thin               4711\n",
       "curvy              3924\n",
       "a little extra     2629\n",
       "skinny             1777\n",
       "full figured       1009\n",
       "overweight          444\n",
       "jacked              421\n",
       "used up             355\n",
       "rather not say      198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.body_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\2869586790.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['body_type'] = mc_data['body_type'].map(body_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "lean            17422\n",
       "muscular        12240\n",
       "curvy            6553\n",
       "fuller           1453\n",
       "other_unkown      553\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge categories in the 'body_type' feature for model simplification\n",
    "# Create a mapping dictionary \n",
    "body_mapping = {\n",
    "    'thin': 'lean',\n",
    "    'skiny': 'lean',\n",
    "    'fit': 'lean',\n",
    "    'curvy': 'curvy',\n",
    "    'a little extra': 'curvy',\n",
    "    'full figured': 'fuller',\n",
    "    'overweight': 'fuller',\n",
    "    'athletic': 'muscular',\n",
    "    'jacked': 'muscular',\n",
    "    'used up': 'other_unkown',\n",
    "    'rather not say': 'other_unkown'    \n",
    "}\n",
    "\n",
    "# Apply mapping to the body_type feature\n",
    "mc_data['body_type'] = mc_data['body_type'].map(body_mapping)\n",
    "mc_data.body_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    23959\n",
       "graduated from masters program        8961\n",
       "working on college/university         5712\n",
       "working on masters program            1683\n",
       "graduated from two-year college       1531\n",
       "graduated from high school            1428\n",
       "graduated from ph.d program           1272\n",
       "graduated from law school             1122\n",
       "working on two-year college           1074\n",
       "dropped out of college/university      995\n",
       "working on ph.d program                983\n",
       "college/university                     801\n",
       "graduated from space camp              657\n",
       "dropped out of space camp              523\n",
       "graduated from med school              446\n",
       "working on space camp                  445\n",
       "working on law school                  269\n",
       "two-year college                       222\n",
       "working on med school                  212\n",
       "dropped out of two-year college        191\n",
       "dropped out of masters program         140\n",
       "masters program                        136\n",
       "dropped out of ph.d program            127\n",
       "dropped out of high school             102\n",
       "high school                             96\n",
       "working on high school                  87\n",
       "space camp                              58\n",
       "ph.d program                            26\n",
       "law school                              19\n",
       "dropped out of law school               18\n",
       "dropped out of med school               12\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\3098079619.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['education'] = mc_data['education'].apply(simplify_education)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "education\n",
       "college or less                  34485\n",
       "graduate degree or less          10920\n",
       "doctorate/professional school     4517\n",
       "high school or less               1713\n",
       "other                             1683\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simplify_education(education):\n",
    "    # Check on missing values and return them as np.NaN\n",
    "    if pd.isna(education):\n",
    "        return np.NaN\n",
    "    #Convert education to string and lower case\n",
    "    education = str(education).lower()\n",
    "\n",
    "    # Check for keywords in the education field and return the new category\n",
    "    if 'high school' in education:\n",
    "        return 'high school or less'\n",
    "    elif 'college' in education:\n",
    "        return 'college or less'\n",
    "    elif 'masters program' in education:\n",
    "        return 'graduate degree or less'\n",
    "    elif 'space' in education: \n",
    "        return 'other'\n",
    "    elif 'ph.d program' in education:\n",
    "        return 'doctorate/professional school'\n",
    "    elif 'law' in education:\n",
    "        return 'doctorate/professional school'\n",
    "    elif 'med' in education:\n",
    "        return 'doctorate/professional school'   \n",
    "\n",
    "mc_data['education'] = mc_data['education'].apply(simplify_education)\n",
    "mc_data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethnicity\n",
      "white                                                                 32831\n",
      "asian                                                                  6134\n",
      "hispanic / latin                                                       2823\n",
      "black                                                                  2008\n",
      "other                                                                  1706\n",
      "                                                                      ...  \n",
      "middle eastern, indian, white                                             1\n",
      "asian, middle eastern, black, white, other                                1\n",
      "asian, middle eastern, indian, hispanic / latin, white, other             1\n",
      "black, native american, indian, pacific islander, hispanic / latin        1\n",
      "asian, black, indian                                                      1\n",
      "Name: count, Length: 217, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mc_data.ethnicity.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian, white' 'white' nan 'asian, black, other' 'white, other'\n",
      " 'hispanic / latin, white' 'hispanic / latin' 'pacific islander, white'\n",
      " 'asian' 'black, white' 'pacific islander' 'asian, native american'\n",
      " 'asian, pacific islander' 'black, native american, white'\n",
      " 'middle eastern, other' 'native american, white' 'indian' 'black'\n",
      " 'black, native american, hispanic / latin, other'\n",
      " 'black, native american, hispanic / latin'\n",
      " 'asian, black, pacific islander'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'other' 'hispanic / latin, other' 'asian, black' 'middle eastern, white'\n",
      " 'native american, white, other' 'black, native american'\n",
      " 'black, white, other' 'hispanic / latin, white, other' 'middle eastern'\n",
      " 'black, other' 'native american, hispanic / latin, white' 'black, indian'\n",
      " 'indian, white, other' 'middle eastern, indian, other'\n",
      " 'black, native american, hispanic / latin, white, other'\n",
      " 'pacific islander, hispanic / latin' 'black, hispanic / latin, white'\n",
      " 'native american' 'indian, white' 'asian, white, other'\n",
      " 'black, hispanic / latin' 'asian, hispanic / latin, white'\n",
      " 'middle eastern, hispanic / latin'\n",
      " 'asian, black, native american, pacific islander, white'\n",
      " 'middle eastern, indian' 'asian, indian' 'pacific islander, other'\n",
      " 'black, native american, white, other' 'black, pacific islander'\n",
      " 'middle eastern, native american, white'\n",
      " 'asian, native american, white, other'\n",
      " 'pacific islander, hispanic / latin, white' 'indian, other'\n",
      " 'asian, pacific islander, other' 'black, hispanic / latin, other'\n",
      " 'asian, black, native american'\n",
      " 'black, native american, hispanic / latin, white'\n",
      " 'native american, hispanic / latin' 'indian, hispanic / latin'\n",
      " 'native american, pacific islander'\n",
      " 'asian, black, native american, hispanic / latin, white'\n",
      " 'asian, black, white'\n",
      " 'asian, black, native american, pacific islander, other'\n",
      " 'middle eastern, hispanic / latin, white'\n",
      " 'asian, pacific islander, white'\n",
      " 'asian, native american, hispanic / latin, white, other'\n",
      " 'asian, hispanic / latin' 'asian, pacific islander, white, other'\n",
      " 'middle eastern, white, other'\n",
      " 'asian, pacific islander, hispanic / latin'\n",
      " 'black, native american, indian, other'\n",
      " 'native american, hispanic / latin, white, other'\n",
      " 'black, native american, other' 'asian, other'\n",
      " 'middle eastern, hispanic / latin, other'\n",
      " 'pacific islander, hispanic / latin, white, other'\n",
      " 'asian, black, hispanic / latin'\n",
      " 'asian, pacific islander, hispanic / latin, white'\n",
      " 'asian, black, native american, white'\n",
      " 'asian, middle eastern, white, other'\n",
      " 'native american, pacific islander, hispanic / latin'\n",
      " 'asian, native american, white'\n",
      " 'native american, pacific islander, hispanic / latin, white, other'\n",
      " 'indian, pacific islander' 'asian, middle eastern, black'\n",
      " 'asian, middle eastern, indian' 'asian, middle eastern, white'\n",
      " 'pacific islander, white, other'\n",
      " 'black, pacific islander, hispanic / latin' 'asian, middle eastern'\n",
      " 'asian, hispanic / latin, other'\n",
      " 'middle eastern, black, native american, indian, white, other'\n",
      " 'middle eastern, pacific islander, other' 'middle eastern, black'\n",
      " 'asian, indian, pacific islander'\n",
      " 'black, native american, pacific islander' 'native american, indian'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'black, indian, other'\n",
      " 'asian, middle eastern, indian, hispanic / latin, white, other'\n",
      " 'middle eastern, black, white' 'asian, hispanic / latin, white, other'\n",
      " 'native american, hispanic / latin, other'\n",
      " 'middle eastern, black, pacific islander, white'\n",
      " 'asian, black, native american, hispanic / latin'\n",
      " 'native american, other' 'black, indian, white'\n",
      " 'asian, native american, hispanic / latin, white'\n",
      " 'black, native american, indian, white'\n",
      " 'middle eastern, black, indian, pacific islander, hispanic / latin, white'\n",
      " 'middle eastern, hispanic / latin, white, other'\n",
      " 'asian, black, native american, other'\n",
      " 'native american, pacific islander, hispanic / latin, white'\n",
      " 'asian, indian, other'\n",
      " 'middle eastern, native american, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander, hispanic / latin, white'\n",
      " 'black, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, native american, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, indian, white' 'native american, pacific islander, white, other'\n",
      " 'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, other' 'middle eastern, pacific islander'\n",
      " 'asian, black, hispanic / latin, other'\n",
      " 'asian, middle eastern, black, native american, hispanic / latin, white'\n",
      " 'middle eastern, black, hispanic / latin'\n",
      " 'black, pacific islander, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other'\n",
      " 'middle eastern, black, native american, indian, hispanic / latin, white'\n",
      " 'asian, pacific islander, hispanic / latin, white, other'\n",
      " 'middle eastern, indian, white' 'asian, indian, white, other'\n",
      " 'middle eastern, black, native american, white, other'\n",
      " 'black, native american, pacific islander, other'\n",
      " 'middle eastern, black, native american, white'\n",
      " 'asian, indian, pacific islander, other'\n",
      " 'asian, black, native american, white, other'\n",
      " 'black, indian, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, white'\n",
      " 'asian, black, pacific islander, hispanic / latin'\n",
      " 'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, black, native american, indian'\n",
      " 'asian, black, indian, hispanic / latin, other'\n",
      " 'indian, hispanic / latin, other' 'asian, indian, hispanic / latin'\n",
      " 'asian, native american, pacific islander, white, other'\n",
      " 'asian, black, native american, indian, hispanic / latin, white, other'\n",
      " 'asian, indian, hispanic / latin, white'\n",
      " 'pacific islander, hispanic / latin, other'\n",
      " 'asian, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'indian, hispanic / latin, white'\n",
      " 'asian, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, pacific islander, hispanic / latin, other'\n",
      " 'asian, black, hispanic / latin, white, other'\n",
      " 'black, indian, hispanic / latin'\n",
      " 'middle eastern, black, native american, hispanic / latin, white'\n",
      " 'black, pacific islander, other'\n",
      " 'black, native american, pacific islander, white'\n",
      " 'asian, black, native american, pacific islander'\n",
      " 'asian, indian, hispanic / latin, other'\n",
      " 'middle eastern, native american'\n",
      " 'middle eastern, native american, hispanic / latin'\n",
      " 'black, hispanic / latin, white, other'\n",
      " 'asian, native american, pacific islander, hispanic / latin, white'\n",
      " 'asian, native american, hispanic / latin'\n",
      " 'black, native american, indian, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, hispanic / latin, white'\n",
      " 'black, native american, pacific islander, white, other'\n",
      " 'native american, indian, pacific islander, hispanic / latin'\n",
      " 'black, indian, white, other'\n",
      " 'asian, middle eastern, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'native american, pacific islander, white'\n",
      " 'middle eastern, indian, white, other' 'asian, black, white, other'\n",
      " 'middle eastern, native american, hispanic / latin, white'\n",
      " 'indian, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander'\n",
      " 'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, indian, other'\n",
      " 'asian, middle eastern, black, white, other'\n",
      " 'black, native american, pacific islander, hispanic / latin, white'\n",
      " 'black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, black, pacific islander, white'\n",
      " 'middle eastern, pacific islander, hispanic / latin'\n",
      " 'black, native american, indian, white, other'\n",
      " 'asian, black, hispanic / latin, white'\n",
      " 'asian, black, native american, indian, pacific islander, white'\n",
      " 'asian, black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, middle eastern, hispanic / latin, white, other'\n",
      " 'middle eastern, black, native american, indian'\n",
      " 'asian, native american, pacific islander'\n",
      " 'asian, black, native american, pacific islander, white, other'\n",
      " 'asian, middle eastern, hispanic / latin'\n",
      " 'asian, black, pacific islander, other'\n",
      " 'asian, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'middle eastern, native american, white, other'\n",
      " 'asian, native american, hispanic / latin, other'\n",
      " 'native american, indian, white'\n",
      " 'black, native american, pacific islander, hispanic / latin'\n",
      " 'asian, native american, pacific islander, white'\n",
      " 'black, native american, indian'\n",
      " 'indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, middle eastern, indian, hispanic / latin'\n",
      " 'asian, middle eastern, native american, pacific islander, other'\n",
      " 'black, native american, indian, pacific islander'\n",
      " 'asian, middle eastern, native american, pacific islander, white, other'\n",
      " 'asian, native american, other' 'middle eastern, black, other'\n",
      " 'asian, black, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander, hispanic / latin'\n",
      " 'asian, black, pacific islander, white, other' 'asian, black, indian']\n"
     ]
    }
   ],
   "source": [
    "print(mc_data.ethnicity.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\767781249.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['ethnicity'] = mc_data['ethnicity'].apply(simplify_ethnicity)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white               33925\n",
       "asian                6291\n",
       "mixed ethnicity      4973\n",
       "hispanic / latin     3059\n",
       "other                2898\n",
       "black                2292\n",
       "pacific islander      460\n",
       "middle eastern        368\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to simplify 'ethnicity' \n",
    "def simplify_ethnicity(ethnicity):\n",
    "    if pd.isna(ethnicity):\n",
    "        return np.NaN\n",
    "    # Convert to lowercase for case sensitive matching\n",
    "    ethnicity = ethnicity.lower()\n",
    "\n",
    "    # Define groups' keywords\n",
    "    white = ['white']\n",
    "    black = ['black']\n",
    "    asian = ['asian', 'indian']\n",
    "    hispanic = ['hispanic', 'latin']\n",
    "    native_american = ['native american']\n",
    "    pacific_islander = ['pacific islander']\n",
    "    middle_eastern = ['middle eastern']\n",
    "\n",
    "    # Create a list to store the detected categories\n",
    "    detected_groups = []\n",
    "    # Check category group\n",
    "    if any(keyword in ethnicity for keyword in white):\n",
    "        detected_groups.append('white')\n",
    "    if any(keyword in ethnicity for keyword in black):\n",
    "        detected_groups.append('black')\n",
    "    if any(keyword in ethnicity for keyword in asian):\n",
    "        detected_groups.append('asian')\n",
    "    if any(keyword in ethnicity for keyword in hispanic):\n",
    "        detected_groups.append('hispanic / latin')\n",
    "    if any(keyword in ethnicity for keyword in pacific_islander):\n",
    "        detected_groups.append('pacific islander')\n",
    "    if any(keyword in ethnicity for keyword in middle_eastern):\n",
    "        detected_groups.append('middle eastern')\n",
    "\n",
    "    # Control for mixed ethnicity\n",
    "    if len(detected_groups) > 1:\n",
    "        return 'mixed ethnicity'\n",
    "    # If one group is detected\n",
    "    if detected_groups:\n",
    "        return detected_groups[0]\n",
    "    # If no recognized group\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "mc_data['ethnicity'] = mc_data['ethnicity'].apply(simplify_ethnicity)\n",
    "mc_data['ethnicity'].value_counts()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\3432554136.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['offspring'] = mc_data['offspring'].str.replace('&rsquo;', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "doesnt have kids                         7560\n",
       "doesnt have kids, but might want them    3875\n",
       "doesnt have kids, but wants them         3565\n",
       "doesnt want kids                         2927\n",
       "has kids                                 1883\n",
       "has a kid                                1881\n",
       "doesnt have kids, and doesnt want any    1132\n",
       "has kids, but doesnt want more            442\n",
       "has a kid, but doesnt want more           275\n",
       "has a kid, and might want more            231\n",
       "wants kids                                225\n",
       "might want kids                           182\n",
       "has kids, and might want more             115\n",
       "has a kid, and wants more                  71\n",
       "has kids, and wants more                   21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data['offspring'] = mc_data['offspring'].str.replace('&rsquo;', '')\n",
    "mc_data.offspring.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\697673924.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['offspring'] = mc_data['offspring'].apply(simplify_offspring)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "no               19466\n",
       "more than one     2461\n",
       "one               2458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to simplify offspring\n",
    "def simplify_offspring(offspring):\n",
    "    if pd.isna(offspring):\n",
    "        return np.NaN\n",
    "    if 'doesnt have' in offspring:\n",
    "        return 'no'\n",
    "    elif 'has a kid' in offspring:\n",
    "        return 'one'\n",
    "    elif 'has kids' in offspring:\n",
    "        return 'more than one'\n",
    "    else:\n",
    "        return 'no'\n",
    "\n",
    "mc_data['offspring'] = mc_data['offspring'].apply(simplify_offspring)\n",
    "mc_data.offspring.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "likes dogs and likes cats          14814\n",
       "likes dogs                          7224\n",
       "likes dogs and has cats             4313\n",
       "has dogs                            4134\n",
       "has dogs and likes cats             2333\n",
       "likes dogs and dislikes cats        2029\n",
       "has dogs and has cats               1474\n",
       "has cats                            1406\n",
       "likes cats                          1063\n",
       "has dogs and dislikes cats           552\n",
       "dislikes dogs and likes cats         240\n",
       "dislikes dogs and dislikes cats      196\n",
       "dislikes cats                        122\n",
       "dislikes dogs and has cats            81\n",
       "dislikes dogs                         44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.pets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\2050907996.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['pets'] = mc_data['pets'].apply(lambda x: 'yes' if isinstance(x,str) and 'has' in x else x if x is None else 'no')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pets\n",
       "no     45653\n",
       "yes    14293\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data['pets'] = mc_data['pets'].apply(lambda x: 'yes' if isinstance(x,str) and 'has' in x else x if x is None else 'no')\n",
    "mc_data.pets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristinaFC\\AppData\\Local\\Temp\\ipykernel_23244\\2926236758.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mc_data['religion'] = mc_data['religion'].apply(simplify_religion)\n"
     ]
    }
   ],
   "source": [
    " # Create a function to simplify religion\n",
    "def simplify_religion(religion):\n",
    "    # Control for nul values\n",
    "    if pd.isna(religion):\n",
    "        return np.NaN\n",
    "    # Check for keyword in the religion field\n",
    "    if 'agnosticism' in religion:\n",
    "        return 'agnosticism'\n",
    "    elif 'catholicism' in religion:\n",
    "        return 'christianity'\n",
    "    elif 'christianity' in religion:\n",
    "        return 'christianity'\n",
    "    elif 'atheism' in religion:\n",
    "        return 'atheism'\n",
    "    elif 'judaism' in religion:\n",
    "        return 'judaism'\n",
    "    elif 'buddhism' in religion:\n",
    "        return 'buddhism'\n",
    "    elif 'hinduism' in religion:\n",
    "        return 'hinduism'\n",
    "    elif 'islam' in religion:\n",
    "        return 'islam'\n",
    "    elif 'other' in religion:\n",
    "        return 'other'\n",
    "\n",
    "mc_data['religion'] = mc_data['religion'].apply(simplify_religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "christianity    10545\n",
       "agnosticism      8812\n",
       "other            7743\n",
       "atheism          6985\n",
       "judaism          3098\n",
       "buddhism         1948\n",
       "hinduism          450\n",
       "islam             139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.religion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38221</td>\n",
       "      <td>35551</td>\n",
       "      <td>56961</td>\n",
       "      <td>45866</td>\n",
       "      <td>53318</td>\n",
       "      <td>54266</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "      <td>51748</td>\n",
       "      <td>24385</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>39720</td>\n",
       "      <td>59946</td>\n",
       "      <td>48890</td>\n",
       "      <td>54434</td>\n",
       "      <td>59896</td>\n",
       "      <td>59946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>7647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>lean</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>college or less</td>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "      <td>straight</td>\n",
       "      <td>no</td>\n",
       "      <td>christianity</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17422</td>\n",
       "      <td>27881</td>\n",
       "      <td>41780</td>\n",
       "      <td>37724</td>\n",
       "      <td>34485</td>\n",
       "      <td>33925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7589</td>\n",
       "      <td>19466</td>\n",
       "      <td>51606</td>\n",
       "      <td>45653</td>\n",
       "      <td>10545</td>\n",
       "      <td>35829</td>\n",
       "      <td>1782</td>\n",
       "      <td>43896</td>\n",
       "      <td>21828</td>\n",
       "      <td>55697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       body_type      diet    drinks  drugs        education ethnicity  \\\n",
       "count      38221     35551     56961  45866            53318     54266   \n",
       "unique         5         6         6      3                5         8   \n",
       "top         lean  anything  socially  never  college or less     white   \n",
       "freq       17422     27881     41780  37724            34485     33925   \n",
       "mean         NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "std          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "min          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "25%          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "50%          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "75%          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "max          NaN       NaN       NaN    NaN              NaN       NaN   \n",
       "\n",
       "              height          income    job offspring orientation   pets  \\\n",
       "count   59943.000000    59946.000000  51748     24385       59946  59946   \n",
       "unique           NaN             NaN     21         3           3      2   \n",
       "top              NaN             NaN  other        no    straight     no   \n",
       "freq             NaN             NaN   7589     19466       51606  45653   \n",
       "mean       68.295281    20033.222534    NaN       NaN         NaN    NaN   \n",
       "std         3.994803    97346.192104    NaN       NaN         NaN    NaN   \n",
       "min         1.000000       -1.000000    NaN       NaN         NaN    NaN   \n",
       "25%        66.000000       -1.000000    NaN       NaN         NaN    NaN   \n",
       "50%        68.000000       -1.000000    NaN       NaN         NaN    NaN   \n",
       "75%        71.000000       -1.000000    NaN       NaN         NaN    NaN   \n",
       "max        95.000000  1000000.000000    NaN       NaN         NaN    NaN   \n",
       "\n",
       "            religion    sex                                      sign smokes  \\\n",
       "count          39720  59946                                     48890  54434   \n",
       "unique             8      2                                        48      5   \n",
       "top     christianity      m  gemini and it&rsquo;s fun to think about     no   \n",
       "freq           10545  35829                                      1782  43896   \n",
       "mean             NaN    NaN                                       NaN    NaN   \n",
       "std              NaN    NaN                                       NaN    NaN   \n",
       "min              NaN    NaN                                       NaN    NaN   \n",
       "25%              NaN    NaN                                       NaN    NaN   \n",
       "50%              NaN    NaN                                       NaN    NaN   \n",
       "75%              NaN    NaN                                       NaN    NaN   \n",
       "max              NaN    NaN                                       NaN    NaN   \n",
       "\n",
       "         speaks  status  \n",
       "count     59896   59946  \n",
       "unique     7647       5  \n",
       "top     english  single  \n",
       "freq      21828   55697  \n",
       "mean        NaN     NaN  \n",
       "std         NaN     NaN  \n",
       "min         NaN     NaN  \n",
       "25%         NaN     NaN  \n",
       "50%         NaN     NaN  \n",
       "75%         NaN     NaN  \n",
       "max         NaN     NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
